{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc8dfbd",
   "metadata": {},
   "source": [
    "# Handwritten digits Classifier\n",
    "\n",
    "Exercise\n",
    "\n",
    "Use-> Logistic Regression, Decision Tree, Support Vector Machines(SVM)\n",
    "    \n",
    "Train SVM classifier using sklearn digits dataset (i.e. from sklearn.datasets import load_digits) and then,\n",
    "\n",
    "Measure accuracy of your model using different kernels such as rbf and linear.\n",
    "\n",
    "Tune your model further using regularization and gamma parameters and try to come up with highest accurancy score\n",
    "\n",
    "Use 80% of samples as training data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d42b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205687cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(digits)\n",
    "\n",
    "# get data to a dataframe\n",
    "df=pd.DataFrame=(digits.data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310eff3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=digits.data\n",
    "y=digits.target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657ec534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ..., 13.,  1.,  0.],\n",
       "       [ 0.,  0., 15., ...,  6.,  2.,  0.],\n",
       "       [ 0.,  0.,  5., ..., 10.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., 10., ..., 16., 15.,  0.],\n",
       "       [ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  3., 15., ..., 13.,  3.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63e9b8",
   "metadata": {},
   "source": [
    "# Using Support Vector Machines(SVM): A Supervised Classification Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93cd2104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of SVM1 model is:97.78%\n"
     ]
    }
   ],
   "source": [
    "# SVM \n",
    "\n",
    "# TUNING HYPER-PARAMETERS\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# with default tuning parameters\n",
    "model_svc1=SVC()\n",
    "\n",
    "# run1 \n",
    "model_svc1.fit(X_train,y_train)\n",
    "\n",
    "#score\n",
    "acc_svm1=model_svc1.score(X_test,y_test)\n",
    "print(f\"The accuracy of SVM1 model is:{round(acc_svm1*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e7310ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of SVM2 model is:96.94%\n"
     ]
    }
   ],
   "source": [
    "model_svc2=SVC(C=100,kernel='linear')\n",
    "\n",
    "# run2\n",
    "model_svc2.fit(X_train,y_train)\n",
    "\n",
    "#score\n",
    "acc_svm2=model_svc2.score(X_test,y_test)\n",
    "print(f\"The accuracy of SVM2 model is:{round(acc_svm2*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f41dc4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of SVM3 model is:98.33%\n",
      "SVM3 is the best SVM model\n"
     ]
    }
   ],
   "source": [
    "model_svm3=SVC(C=100,kernel='poly')\n",
    "\n",
    "# run2\n",
    "model_svm3.fit(X_train,y_train)\n",
    "\n",
    "#score\n",
    "acc_svm3=model_svc3.score(X_test,y_test)\n",
    "print(f\"The accuracy of SVM3 model is:{round(acc_svm3*100,2)}%\")\n",
    "print('SVM3 is the best SVM model')\n",
    "\n",
    "# get prediction from best svm model\n",
    "y_pred_svm=model_svm3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfc2d3",
   "metadata": {},
   "source": [
    "SVM model with C=100 and kernel='rbf' or 'poly' gives maximum accuracy of 98.33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a776f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 40  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 41  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 30  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 39  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 42  0  0  0  1]\n",
      " [ 0  1  0  0  0  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 22  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 32  0]\n",
      " [ 0  0  0  0  0  1  0  1  1 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.95      1.00      0.98        40\n",
      "           2       1.00      1.00      1.00        41\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00        39\n",
      "           5       0.98      0.98      0.98        43\n",
      "           6       1.00      0.98      0.99        45\n",
      "           7       0.96      1.00      0.98        22\n",
      "           8       0.97      0.97      0.97        33\n",
      "           9       0.97      0.91      0.94        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics for best SVM Model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm_svm=confusion_matrix(y_test,y_pred_svm)\n",
    "print(cm_svm)\n",
    "\n",
    "# \n",
    "print(classification_report(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8331be",
   "metadata": {},
   "source": [
    "# Using Logistic Regression: Multi Class Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d430439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logisitic Rgeression model is:97.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr=LogisticRegression()\n",
    "\n",
    "# Train\n",
    "model_lr.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_lr=model_lr.predict(X_test)\n",
    "\n",
    "# score\n",
    "acc_lr=model_lr.score(X_test,y_test)\n",
    "print(f\"The accuracy of Logisitic Rgeression model is:{round(acc_lr*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619489d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 34  0  1  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 39  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 35  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 33  0  0  0  0]\n",
      " [ 0  0  0  0  0  1 41  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 31  1]\n",
      " [ 0  0  0  1  1  0  0  0  0 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       0.94      0.97      0.96        35\n",
      "           2       0.97      1.00      0.99        33\n",
      "           3       0.93      0.97      0.95        40\n",
      "           4       0.97      1.00      0.99        35\n",
      "           5       0.97      0.97      0.97        34\n",
      "           6       1.00      0.98      0.99        42\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       1.00      0.91      0.95        34\n",
      "           9       0.97      0.94      0.95        33\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics for best SVM Model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm_lr=confusion_matrix(y_test,y_pred_lr)\n",
    "print(cm_lr)\n",
    "\n",
    "# \n",
    "print(classification_report(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c807ffc",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f105588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Decision Tree\n",
    "\n",
    "from sklearn import tree\n",
    "model_dt=tree.DecisionTreeClassifier()\n",
    "\n",
    "model_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "873c9501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the Decision Tree model is: 85.83%\n"
     ]
    }
   ],
   "source": [
    "# score of model\n",
    "acc_dt=model_dt.score(X_test,y_test)\n",
    "print(f\"The score of the Decision Tree model is: {round(acc_dt*100,2)}%\")\n",
    "\n",
    "y_pred_dt=model_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33c4e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 30  0  1  1  0  0  0  3  0]\n",
      " [ 1  0 29  2  0  0  1  0  0  0]\n",
      " [ 0  1  0 31  0  0  0  1  4  3]\n",
      " [ 0  2  0  0 26  1  1  5  0  0]\n",
      " [ 0  1  0  0  2 31  0  0  0  0]\n",
      " [ 0  0  0  1  2  1 38  0  0  0]\n",
      " [ 0  2  0  0  2  0  0 35  0  1]\n",
      " [ 0  3  1  1  0  0  0  0 27  2]\n",
      " [ 0  0  0  1  0  2  0  0  1 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        34\n",
      "           1       0.77      0.86      0.81        35\n",
      "           2       0.97      0.88      0.92        33\n",
      "           3       0.84      0.78      0.81        40\n",
      "           4       0.79      0.74      0.76        35\n",
      "           5       0.86      0.91      0.89        34\n",
      "           6       0.95      0.90      0.93        42\n",
      "           7       0.85      0.88      0.86        40\n",
      "           8       0.77      0.79      0.78        34\n",
      "           9       0.83      0.88      0.85        33\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "cm_dt=confusion_matrix(y_test,y_pred_dt)\n",
    "print(cm_dt)\n",
    "\n",
    "# \n",
    "print(classification_report(y_test,y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47632c25",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "216b754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the Random Forest Classifier is: 98.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf=RandomForestClassifier(n_estimators=250)\n",
    "\n",
    "# train model\n",
    "model_rf.fit(X_train,y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred_rf=model_rf.predict(X_test)\n",
    "\n",
    "# score\n",
    "acc_rf=model_rf.score(X_test,y_test)\n",
    "print(f\"The score of the Random Forest Classifier is: {round(acc_rf*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c812da64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 38  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 37  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 33  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 38  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 30  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 37  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 34  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 34  0]\n",
      " [ 0  0  0  0  0  0  0  0  1 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       1.00      1.00      1.00        38\n",
      "           2       1.00      1.00      1.00        37\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       1.00      0.97      0.99        39\n",
      "           5       0.97      0.97      0.97        31\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       0.97      1.00      0.99        34\n",
      "           8       0.97      1.00      0.99        34\n",
      "           9       0.97      0.97      0.97        37\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "cm_rf=confusion_matrix(y_test,y_pred_rf)\n",
    "print(cm_rf)\n",
    "\n",
    "# \n",
    "print(classification_report(y_test,y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
